{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*prefix_encoder权重混合器*\n",
    "\n",
    "本脚本旨在解决chatglm2-6b ptuning后遗忘原功能的问题\n",
    "\n",
    "\n",
    "思路：\n",
    "ptuning训练的权重本质是练model.transformer.prefix_encoder。\n",
    "因此此脚本将老的prefix_encoder权重和ptuning训练的权重混合一下，再重新注入model.transformer.prefix_encoder中。\n",
    "\n",
    "经过测试老权重0.2，新权重0.8，这样加权平均后的模型能打招呼并保留ptuning训练的能力\n",
    "不过这种平均值混合权重的方法比较玄学，不一定有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基础环境载入\n",
    "#地址输入\n",
    "model_path = \n",
    "ptune_model_path=\n",
    "origin_encoder_save_path='origin_prefix_encoder.pth'\n",
    "mixed_encoder_save_path='mixed_prefix_encoder.pth'\n",
    "#调参\n",
    "origin_p=0.2#混合度(0-1),原始权重保留度\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoConfig\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "\n",
    "# 载入Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "def display_answer(model, query, history=[]):\n",
    "    for response, history in model.stream_chat(\n",
    "            tokenizer, query, history=history):\n",
    "        clear_output(wait=True)\n",
    "        display(Markdown(response))\n",
    "    return history\n",
    "\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_path, trust_remote_code=True, pre_seq_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取原模型\n",
    "model = AutoModel.from_pretrained(model_path,config=config,trust_remote_code=True)\n",
    "model = model.cuda()\n",
    "model = model.eval()\n",
    "# 将模型的状态字典保存到文件中\n",
    "torch.save(model.transformer.prefix_encoder.state_dict(), origin_encoder_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#混合原prefix_encoder权重与adgn权重\n",
    "o_prefix_encoder=dict(torch.load(origin_encoder_save_path))\n",
    "myself_prefix_encoder = torch.load(os.path.join(ptune_model_path, \"pytorch_model.bin\"))\n",
    "mixed_prefix_encoder={}\n",
    "mixed_prefix_encoder['embedding.weight']=origin_p*o_prefix_encoder['embedding.weight']+(1-origin_p)*myself_prefix_encoder['transformer.prefix_encoder.embedding.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存混合权重\n",
    "torch.save(mixed_prefix_encoder, mixed_encoder_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取混合权重\n",
    "mixed_path='mixed_prefix_encoder.pth'\n",
    "mixed_prefix_encoder=torch.load(mixed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#注入混合权重\n",
    "model.transformer.prefix_encoder.load_state_dict(mixed_prefix_encoder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**选择运行**\n",
    "\n",
    "存储整个大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将模型的状态字典保存到文件中\n",
    "torch.save(model.state_dict(), 'saved_model.pth')\n",
    "#将saved_model.pth换掉model_path中的pytorch_model.bin使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#推理\n",
    "history=display_answer(model, \"more\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatglm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17 (default, Jul  5 2023, 20:44:21) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab0faeaae8d3ecf468f0c4865b7518fe18ff8e3064c6f90fc5e4c8ae18c64a55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
